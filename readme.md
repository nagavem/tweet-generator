# Tweet generator 
Objective is to generate short-texts similar in style and content to the tweets of any twitter user with sufficient public tweets. This project has not been and should not be used to impersonate or harass anyone. It is purely out of academic interest. I chose [@realDonaldTrump](https://twitter.com/realDonaldTrump?s=20) as the twitter user as he has been the most prolific and well-known tweeter of our times. 
I implemented this algorithm in two ways-
1. Trained from scratch using LSTM
2. Fine-tuned using [GPT-2-simple](https://github.com/minimaxir/gpt-2-simple)

### LSTM
I trained an LSTM with the following layers on tweets from [@realDonaldTrump](https://twitter.com/realDonaldTrump?s=20) since March, 2019 (about 10k tweets). 
1. An embedding layer to generate word vectors
2. Bidirectional LSTM
3. Dense layer 

This algorithm, being a sequence generator, needs a prompt to generate text. The prompt needs to be minimum one word. This algorithm is limited mainly in two ways:
1. 10k (a limitation imposed by my machine's memory) is too low a number to train a text generation algorithm on 
2. Text generated is not case and punctuation sensitive

As a result, tweets are not grammatically proper and also often randomly switch context mid-tweet. A few example tweets generated by this algorithm:
1. Ivanka has been fired for her and the fake news media is a true winner
2. Wow what a great job on the following respect to the white house lies or fake news media they are doing possible for the election
3. Republicans are great to the great state of minnesota with her speaker and the democrats are doing a great job
4. It is criminal that the fact that the democrats are not going to be the beginning is a disgrace to the great state
5. Sleepy Joe can not be able to do it is the real story like donald trump was not happy that i have done nothing wrong
6. They say that Trump is a corrupt politician who was a clue who would have done more for our country for a lot of market thank you mr trump better than any president in history in the united states 
7. Covid cannot be allowed to do your vote to do your vote for him out of our country the do nothing democrats are doing nothing to get them with the democrats or more than the democrats in the most unfair in history
8. The election was a total mess not why they are doing with you horribly fredo and professional deal good job somewhat chant will be winning anyway that the dems have been doing very bad for our country and israel

### GPT-2-simple
[GPT-2](https://openai.com/blog/better-language-models/) is a transformer-based language model created by openAI. They have also come out with GPT-3 now. GPT-2 has already been trained on 40GB worth of text on internet. It just needs fine-tuning to a more specific corpus of text to get going. [gpt-2-simple](https://github.com/minimaxir/gpt-2-simple) is a repository written by [Max Woolf](https://github.com/minimaxir) which simplifies fine-tuning and the subsequent text-generation process.

I trained (fine-tuned) the model on Google Colab as they provide a GPU and I saved the checkpoint file with all the weights on GCP compute engine to generate new tweets. I also created a twitter bot using tweepy that can be scheduled to tweet periodically via crontab.

Example tweets via this algorithm-
1. Thank you @foxandfriends for your incredible show on Monday night. Really helped keep my promise and will be back soon with @wolfblitzer! Tune in!
2. Just learned that, despite the many challenges, I had the top ratings in my first 12 months. That was a record!
3. My speech at the Statehouse on Tuesday to millions of GREAT people. We will MAKE AMERICA GREAT AGAIN! We are all working together!

# Requirements
Python 3.x (this project uses Python 3.7) and the following Python modules:
* Pandas
* Tensorflow 2.0 (for LSTM)
* Tensorflow 1.15 (for GPT-2-simple; not compatible with Python 3.8)
* Numpy
* Matplotlib
* Snscrape
* gpt_2_simple

# How to use
Clone this project and cd into the main project folder (tweet-generator) in a terminal. Install all the required modules with:
```
pip3 install -r requirements.txt
```
I have not included Tensorflow 1.15 in requirements.txt as it should to be installed in a virtual environment and gpt-2-simple code be run in that virtual environment.

The main project folder contains two sub-folders for the two different methods I tried:

### LSTM
##### Training
- Cd into LSTM folder, open myinputs.py and change the handle to the twitter username you wish. Set mode to 'train'. 
- Run:
```
      python3 get_tweets.py
```
- If tweets downloaded are very large, reduce the number in the xlsx to about 10k (depends on your machine though) 
- Run:
```
      python3 generate_tweets.py
```
##### Tweet generation
- In myinputs.py, set seed_text and next_words (total length of the tweet excluding seed_text) and run:
```
      python3 generate_tweets.py
```

### GPT-2-simple
Cd into the GPT-2simple folder. I have included checkpoiint file trained on tweets from @realDonaldTrump but if you wish to fine-tune GPT-2 for some othwr twitter handle, I have included tweet_gen_gpt2simple.ipynb for that. It is best run in Google Colab on a GPU. You will need to download the training tweets in a .txt file with two tweets seperated by a newline. Once trained, download the checkpoint folder to the GPT-2simple folder. Make sure you are working in the virtual environment in which Tensorflow 1.15 has been installed. Run:
```
      python3 tweet_bot.py
```
To set up a tweet bot, in tweet_bot.py, enter the consumer_key, consumer_secret_key, access_token and access_secret_token generated from a developers twitter account and change mode to 'tweet'. A cronjob can also be scheduled to send out tweets automatically. 
      
